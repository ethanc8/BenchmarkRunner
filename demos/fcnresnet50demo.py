# SPDX-License-Identifier: AGPL-3.0-or-later
# Some of this code is from https://docs.opencv.org/4.x/d7/d9a/pytorch_segm_tutorial_dnn_conversion.html
# Some of this code was generated by ChatGPT-4o
import torch
import torch.onnx
import torchvision
import torchvision.transforms as transforms
import numpy as np
import cv2 as cv
import sys
import os
import solInfer as solInfer
from solInfer.models.fcnresnet50 import FCNResNet50
import numpy as np

def ceildiv(n, d):
    return -(n // -d)

def get_processed_img(img_path: str):
    # read the image
    input_img = cv.imread(img_path, cv.IMREAD_COLOR)
    img = input_img
    input_img = input_img.astype(np.float32)
    # target image sizes
    img_height = input_img.shape[0]
    img_width = input_img.shape[1]
    
    # define preprocess parameters
    mean = np.array([0.485, 0.456, 0.406]) * 255.0
    scale = 1 / 255.0
    std = [0.229, 0.224, 0.225]
    
    # prepare input blob to fit the model input:
    # 1. subtract mean
    # 2. scale to set pixel values from 0 to 1
    input_blob = cv.dnn.blobFromImage(
        image=input_img,
        scalefactor=scale,
        size=(img_width, img_height), # img target size
        mean=mean,
        swapRB=True, # BGR -> RGB
        crop=False # center crop
    )
    # 3. divide by std
    input_blob[0] /= np.asarray(std, dtype=np.float32).reshape(3, 1, 1)

    return img, solInfer.backends.NPTensor(input_blob)

def read_colors_info(filename):
    pascal_voc_classes = []
    pascal_voc_colors = []
    with open(filename) as f:
        for line in f.readlines():
            name, r, g, b = line.split()
            pascal_voc_classes.append(name)
            pascal_voc_colors.append((r, g, b))
    return pascal_voc_classes, pascal_voc_colors

def get_colored_seg_image(seg_map, pascal_voc_colors):
    seg_image = np.zeros((seg_map.shape[0], seg_map.shape[1], 3), dtype=np.uint8)
    for label in range(len(pascal_voc_colors)):
        seg_image[seg_map == label] = pascal_voc_colors[label]
    
    return seg_image

def blend_images(seg_image, image):
    alpha = 0.5
    blended = cv.addWeighted(image, alpha, seg_image, 1 - alpha, 0)
    return blended

if __name__ == "__main__":
    # Get the ResNet50 model and the imagenet labels
    torch_model = FCNResNet50.get_pretrained()

    img, blob = get_processed_img("data/2007_000033.jpg")

    # Convert the model to ONNX and load it with OpenCV DNN
    os.makedirs("tmp/", exist_ok=True)
    onnx_filename = FCNResNet50.convert_to_disk_format(solInfer.models.disk_formats.ONNX, torch_model, "tmp/fcn_resnet50.onnx", image_size=img.shape)
    cv_model = solInfer.backends.cvDNN.Net.loadONNX(onnx_filename)
     
    pascal_voc_classes, pascal_voc_colors = read_colors_info("data/pascal-classes.txt")

    # Run with OpenCV DNN
    print("Inferring with OpenCV DNN...")
    opencv_prediction = FCNResNet50.infer(cv_model, blob)

    # Run with PyTorch
    print("Inferring with PyTorch...")
    pytorch_prediction = FCNResNet50.infer(torch_model, blob)

    # Create segmentation image
    opencv_seg_image = get_colored_seg_image(opencv_prediction, pascal_voc_colors)
    pytorch_seg_image = get_colored_seg_image(pytorch_prediction, pascal_voc_colors)

    # # Blend the original image with the segmentation image
    opencv_blended = blend_images(opencv_seg_image, img)
    pytorch_blended = blend_images(pytorch_seg_image, img)

    # Save and display the result
    # cv.imwrite('segmentation_result.png', blended)
    cv.imshow('OpenCV segmentation', opencv_blended)
    cv.imshow('PyTorch segmentation', pytorch_blended)
    cv.waitKey(0)
    cv.destroyAllWindows()
